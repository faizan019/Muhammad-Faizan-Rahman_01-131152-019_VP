{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4cca9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from functools import reduce\n",
    "import regex as re\n",
    "import warnings\n",
    "import arrow\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "import numpy as np\n",
    "import math\n",
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "from datetime import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d791b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({'alias':['abc','def','ghi','jkl']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f301c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  alias\n",
      "0   abc\n",
      "1   def\n",
      "2   ghi\n",
      "3   jkl\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "918978a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __alias_substrings(df, in_list, col_name='alias'):\n",
    "    df=df[df[col_name].str.contains('|'.join(in_list), case=False)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07f0ea3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  alias\n",
      "0   abc\n",
      "3   jkl\n"
     ]
    }
   ],
   "source": [
    "in_list=['bc','kl']\n",
    "result= __alias_substrings(df,in_list)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a3a93ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_bc\n",
      "j_kl\n",
      "Index(['alias'], dtype='object')\n",
      "['alias']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "    df=pd.DataFrame({'alias':['abc','def','ghi','jkl']})\n",
    "    in_list=['a_bc','j_kl']\n",
    "    groups = in_list\n",
    "    if in_list is not None:\n",
    "        filtered_aliases = []\n",
    "        substrings = []\n",
    "        for group_id in groups:\n",
    "            print(group_id)\n",
    "            substrings.append(group_id.split('_'))\n",
    "        unique_aliases = df.columns\n",
    "        print(unique_aliases)\n",
    "        unique_aliases = list(filter(None, unique_aliases))\n",
    "        print(unique_aliases)\n",
    "    else:\n",
    "        remove_cols = ['time_local']\n",
    "        filtered_aliases = list(set(df.columns.to_list()) - set(remove_cols))\n",
    "    print (filtered_aliases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "845e898f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({'alias':['a_bc','def','ghi','jkl']})\n",
    "in_list=['a_bc','j_kl','heatPump_enable_sensor', 'chiller_enable_sensor']\n",
    "\n",
    "#def __alias_substrings(df, in_list, col_name='alias'):\n",
    "def __alias_substrings(df, in_list, col_name='alias'):\n",
    "        groups = in_list\n",
    "    \n",
    "        if in_list is not None:\n",
    "            filtered_aliases = []\n",
    "            substrings = []\n",
    "            # Creating list of substrings\n",
    "            for group_id in groups:\n",
    "                print(\"group id == > \",group_id)\n",
    "                substrings.append(group_id.split('_'))\n",
    "                print(substrings)\n",
    "            unique_aliases = df.columns\n",
    "            print(unique_aliases)\n",
    "            # Removing None from the list of unique aliases\n",
    "            unique_aliases = list(filter(None, unique_aliases))\n",
    "            # Filter the aliases that are to be used for the KPI\n",
    "            for alias in unique_aliases:\n",
    "                for sub in substrings:\n",
    "                    if all(a.strip() in alias for a in sub):\n",
    "                        #print(alias)\n",
    "                        filtered_aliases.append(alias)\n",
    "        else:\n",
    "            remove_cols = ['time_local']\n",
    "            filtered_aliases = list(set(df.columns.to_list()) - set(remove_cols))\n",
    "        return filtered_aliases\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7c16b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group id == >  a_bc\n",
      "[['a', 'bc']]\n",
      "group id == >  j_kl\n",
      "[['a', 'bc'], ['j', 'kl']]\n",
      "group id == >  heatPump_enable_sensor\n",
      "[['a', 'bc'], ['j', 'kl'], ['heatPump', 'enable', 'sensor']]\n",
      "group id == >  chiller_enable_sensor\n",
      "[['a', 'bc'], ['j', 'kl'], ['heatPump', 'enable', 'sensor'], ['chiller', 'enable', 'sensor']]\n",
      "Index(['alias'], dtype='object')\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "result= __alias_substrings(df,in_list)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "384b8c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([1,1,2,1,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53460a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A    0\n",
      "B    2\n",
      "C    1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create a sample dataframe\n",
    "df = pd.DataFrame({\n",
    "    'A': [1, 2, 3, 4],\n",
    "    'B': [5, None, None, 8],\n",
    "    'C': [9, 10, None, 12]\n",
    "})\n",
    "\n",
    "# check for missing values in each column\n",
    "missing_values = df.isna().sum()\n",
    "\n",
    "print(missing_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "f47cbbeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A  B  C\n",
      "0  1  4  7\n",
      "1  2  5  8\n",
      "2  3  6  9\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df= pd.DataFrame({'A':[1,2,3], 'B': [4,5,6], 'C':[7,8,9]})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "c9954e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_column = df.loc[[0,2],['A','C','B']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "7cfac463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>C</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  C  B\n",
       "0  1  7  4\n",
       "2  3  9  6"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "fa6e426c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_data = df.loc[[0,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "4325722b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_data1=df.loc[:,'A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "e0c6e98e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    3\n",
       "Name: A, dtype: int64"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ext_data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "17d7a072",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({\"value\":['True','False','True','True','False','False']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9c0410e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"value\"] == True, \"value\"] = 1\n",
    "df.loc[df[\"value\"] == False, \"value\"] = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a39a6520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     True\n",
      "1    False\n",
      "2     True\n",
      "3     True\n",
      "4    False\n",
      "5    False\n",
      "Name: value, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.loc[:,'value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "567fb351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     True\n",
      "1     True\n",
      "2     True\n",
      "3    False\n",
      "4     True\n",
      "5    False\n",
      "Name: expected_streak, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "df['expected_streak'] = df.value.ne(df.value.shift())\n",
    "print(df['expected_streak'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f4c4cc29",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'time_local'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3803\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'time_local'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# get timelocal for the start of streak\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstreak_time\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpected_streak\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtime_local\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#print(df['streak_time'])\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:3805\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3804\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3805\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3807\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3810\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'time_local'"
     ]
    }
   ],
   "source": [
    "# get timelocal for the start of streak\n",
    "df['streak_time'] = df.loc[df.expected_streak == True]['time_local']\n",
    "#print(df['streak_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6f47b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert streak start time to datetime\n",
    "df['streak_time'] = pd.to_datetime(df['streak_time'])\n",
    "# converte time_local to datetime\n",
    "df['time_local'] = pd.to_datetime(df['time_local'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "f96f20c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   value  expected_streak\n",
      "0   True             True\n",
      "1  False             True\n",
      "2   True             True\n",
      "3   True            False\n",
      "4  False             True\n",
      "5  False            False\n"
     ]
    }
   ],
   "source": [
    "# fill null values from previous values by using forward filling\n",
    "df = df.fillna(method='ffill')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "e7957da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate delta in minutes\n",
    "df['delta'] = (df['time_local'] - df['streak_time']\n",
    "                ).dt.total_seconds() / 60\n",
    "return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "a58b3c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eq=pd.DataFrame({\"equation\":['alias_a > 90']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "916a8bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_equation_1(self, df=None, equation=None, temp=None):\n",
    "        \"\"\" This function basically takes a dataframe and an equation\n",
    "        and then tries to apply this equation and results in the form of boolean.\n",
    "        Parameters\n",
    "        ----------\n",
    "        df: Dataframe\n",
    "        A Dataframe for an aliases or a pair of aliases\n",
    "        equation: String\n",
    "        This string has a set of instruction\n",
    "        Returns\n",
    "        -------\n",
    "        df: Dataframe\n",
    "        \"\"\"\n",
    "        def func(x):\n",
    "            y = eval(equation)\n",
    "            return y\n",
    "        if df.shape[0] > 0:\n",
    "            df['time_local'] = pd.to_datetime(df['time_local'])\n",
    "            # in case equation is given and not missing_values or constant values\n",
    "            if equation is not None:\n",
    "                # iterate for given given alias columns in the config file\n",
    "                for col in self.__res:\n",
    "                    # add dataframe with alias column\n",
    "                    if col in equation:\n",
    "                        col_name = f\"x['{col}']\"\n",
    "                        equation = equation.replace(col, col_name)\n",
    "                # time and date based conditions\n",
    "                if 'day' in equation:\n",
    "                    df['day'] = df.time_local.dt.dayofweek\n",
    "                    equation = equation.replace('day', 'x[\"day\"]')\n",
    "                if 'date' in equation:\n",
    "                    df['date'] = df.time_local.dt.date\n",
    "                    equation = equation.replace('date', 'str(x[\"date\"])')\n",
    "                if 'time' in equation:\n",
    "                    df['time'] = df.time_local.apply(lambda x: x.strftime('%H:%M'))\n",
    "                    equation = equation.replace('time', 'str(x[\"time\"])')\n",
    "                if 'hour' in equation:\n",
    "                    df['hour'] = df.time_local.dt.hour\n",
    "                    equation = equation.replace('hour', 'x[\"hour\"]')\n",
    "                if 'minute' in equation:\n",
    "                    df['minute'] = df.time_local.dt.minute\n",
    "                    equation = equation.replace('minute', 'x[\"minute\"]')\n",
    "                if 'month' in equation:\n",
    "                    df['month'] = df.time_local.dt.month\n",
    "                    equation = equation.replace('month', 'x[\"month\"]')\n",
    "                # apply equation\n",
    "                df['value'] = df.apply(func, axis=1)\n",
    "            # in case equation is None\n",
    "            else:\n",
    "                df['value'] = df['alias_a']\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "d6d99c97",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[226], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m df \u001b[38;5;241m=\u001b[39m apply_equation_1(\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m, df, equation\u001b[38;5;241m=\u001b[39mrule[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mequation_1\u001b[39m\u001b[38;5;124m'\u001b[39m], temp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "df = apply_equation_1(\n",
    "    self, df, equation=rule['equation_1'], temp=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "9e22e09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    y = eval(equation)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "3a135967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.5.2'"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "d6b41697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    a\n",
       "3    C\n",
       "dtype: object"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Pandas Series Object\n",
    "data= pd.Series([0.25,0.5,0.75,1])\n",
    "data\n",
    "\n",
    "#values as simple NumPy arrays\n",
    "data.values\n",
    "\n",
    "#index is an array like object of type pd.index\n",
    "data.index\n",
    "\n",
    "data[1]\n",
    "data[:3]\n",
    "data[::3]\n",
    "\n",
    "\n",
    "#Series as generalized NumPy array\n",
    "data=pd.Series([0.25, 0.5, 0.75, 1.00], index=['a','b','c','d'])\n",
    "data\n",
    "\n",
    "\n",
    "data=pd.Series([0.25,0.5,0.75,1], index=['a','b','c','d'])\n",
    "data\n",
    "\n",
    "data['b']\n",
    "\n",
    "#Series as generalized NumPy array\n",
    "data=pd.Series([0.25,0.5,0.75,1], index=[2,4,6,8])\n",
    "data\n",
    "\n",
    "#Series as specialized dictionary\n",
    "population_dict={ 'California':38332521,\n",
    "                 'Texas' : 25656565,\n",
    "                 'New York' : 12132121,\n",
    "                 'Florida' : 23232323,\n",
    "                 'Illinois' :15142122    \n",
    "}\n",
    "population = pd.Series(population_dict)\n",
    "population\n",
    "\n",
    "population['Texas']\n",
    "\n",
    "pd.Series([2,4,6])\n",
    "\n",
    "pd.Series(5, index=[100,200,300])\n",
    "pd.Series(8, index=[100,200,300])\n",
    "\n",
    "\n",
    "#data can be a dictionary, in which index defaults to the sorted dictionary keys\n",
    "pd.Series({2:'a', 1:'b', 3:'c'})\n",
    "\n",
    "pd.Series({2:'a', 1:'b', 3:'C'}, index=[2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "7b265994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>population</th>\n",
       "      <th>area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>California</th>\n",
       "      <td>38332521</td>\n",
       "      <td>426484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Texas</th>\n",
       "      <td>25656565</td>\n",
       "      <td>145644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New York</th>\n",
       "      <td>12132121</td>\n",
       "      <td>459684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Florida</th>\n",
       "      <td>23232323</td>\n",
       "      <td>850215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Illinois</th>\n",
       "      <td>15142122</td>\n",
       "      <td>859564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            population    area\n",
       "California    38332521  426484\n",
       "Texas         25656565  145644\n",
       "New York      12132121  459684\n",
       "Florida       23232323  850215\n",
       "Illinois      15142122  859564"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The Pandas DataFrame Object\n",
    "\n",
    "#DataFrame as a generalized NumPy array\n",
    "area_dict={'California': 426484,\n",
    "          'Texas': 145644,\n",
    "           'New York':459684,\n",
    "            'Florida': 850215,\n",
    "             'Illinois':859564}\n",
    "area=pd.Series(area_dict)\n",
    "area\n",
    "\n",
    "states=pd.DataFrame({'population':population,\n",
    "                    'area': area})\n",
    "states\n",
    "\n",
    "states.index\n",
    "states.columns\n",
    "\n",
    "\n",
    "#DataFrame as specialized dictionary\n",
    "states['area']\n",
    "\n",
    "\n",
    "#Constructing DataFrame objects\n",
    "#From a single Series object\n",
    "pd.DataFrame(population, columns=['population'])\n",
    "\n",
    "#From a list of dicts\n",
    "data = [{'a': i, 'b': 2*i}\n",
    "           for i in range(3)]\n",
    "data\n",
    "pd.DataFrame(data)\n",
    "\n",
    "data= [{'a':i, 'b' :2*i}\n",
    "          for i in range(3)]\n",
    "pd.DataFrame(data)\n",
    "\n",
    "#if we have missing values pd give NaN(not a number)\n",
    "pd.DataFrame([{'a':1, 'b':2}, {'b':3, 'c':4}])\n",
    "\n",
    "\n",
    "#From a dictionary of Series objects\n",
    "pd.DataFrame({'population': population,\n",
    "                'area': area})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "49a64c3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3\n",
       "0  1.0  1.0  2.0  2.0\n",
       "1  2.0  3.0  5.0  5.0\n",
       "2  NaN  4.0  6.0  6.0"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Handling Missing Data\n",
    "vals=np.array([1, None, 3, 4])\n",
    "vals\n",
    "#vals.sum() will give error\n",
    "\n",
    "#NaN: Missing numerical data\n",
    "vals1=np.array([1, np.nan, 3, 4])\n",
    "vals1\n",
    "vals1.dtype\n",
    "\n",
    "1+np.nan\n",
    "\n",
    "0*np.nan\n",
    "\n",
    "vals1.sum(), vals1.min(), vals1.max()\n",
    "\n",
    "\n",
    "np.nansum(vals1), np.nanmin(vals1), np.nanmax(vals1)\n",
    "\n",
    "pd.Series([1, np.nan, 3, None])\n",
    "\n",
    "vals2=pd.Series(range(5), dtype='int')\n",
    "vals2\n",
    "vals2[0]=[None]\n",
    "vals2\n",
    "\n",
    "#in Pandas, string data is always stored with an object dtype.\n",
    "#isnull(): Generate a boolean mask indicating missing values\n",
    "#notnull(): Opposite of isnull()\n",
    "#dropna(): Return a filtered version of the data\n",
    "#fillna(): Return a copy of the data with missing values filled or imputed\n",
    "\n",
    "\n",
    "#Pandas data structures have two useful methods for detecting null data: isnull() and notnull(). Either one will return a \n",
    "#Boolean mask over the data. For example:\n",
    "x=pd.Series([1, np.nan, 'Hello', None])\n",
    "x\n",
    "x.isnull()\n",
    "\n",
    "x[x.notnull()]\n",
    "\n",
    "x.dropna()\n",
    "\n",
    "df=pd.DataFrame([[1, np.nan, 2],\n",
    "                [2,3,5],\n",
    "                [np.nan, 4, 6]])\n",
    "df\n",
    "\n",
    "df.dropna()\n",
    "\n",
    "df.dropna(axis = 'columns')\n",
    "\n",
    "#But this drops some good data as well; you might rather be interested in dropping rows or columns with all NA values, \n",
    "#or a majority of NA values. This can be specified through the how or thresh parameters, which allow fine control of the \n",
    "#number of nulls to allow through.\n",
    "\n",
    "#The default is how='any', such that any row or column (depending on the axis keyword) containing a null value will be dropped. \n",
    "#You can also specify how='all', which will only drop rows/columns that are all null values:\n",
    "\n",
    "df[3]=np.nan\n",
    "df\n",
    "df.dropna(axis='columns', how='all')\n",
    "\n",
    "#For finer-grained control, the thresh parameter lets you specify a minimum number of non-null values for the row/column \n",
    "#to be kept:\n",
    "df.dropna(axis ='rows', thresh=3)\n",
    "\n",
    "\n",
    "#Filling null values\n",
    "data=pd.Series([1, np.nan, 2, None, 3], index=list('abcde'))\n",
    "data\n",
    "data.fillna(0)\n",
    "\n",
    "#We can specify a forward-fill to propagate the previous value forward:\n",
    "data.fillna(method='ffill')\n",
    "\n",
    "#Or we can specify a back-fill to propagate the next values backward:\n",
    "data.fillna(method='bfill')\n",
    "\n",
    "\n",
    "#For dataframe\n",
    "#For DataFrames, the options are similar, but we can also specify an axis along which the fills take place:\n",
    "df\n",
    "df.fillna(method='ffill')\n",
    "df.fillna(method='ffill', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "e8a30fc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>Bob</th>\n",
       "      <th>Guido</th>\n",
       "      <th>Sue</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>HR</th>\n",
       "      <th>HR</th>\n",
       "      <th>HR</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th>visit</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <th>1</th>\n",
       "      <td>42.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <th>1</th>\n",
       "      <td>29.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "subject      Bob Guido   Sue\n",
       "type          HR    HR    HR\n",
       "year visit                  \n",
       "2013 1      42.0  40.0  33.0\n",
       "2014 1      29.0  49.0  47.0"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hierarchical Indexing\n",
    "#make use of hierarchical indexing (also known as multi-indexing) to incorporate multiple index levels within a single index. \n",
    "#In this way, higher-dimensional data can be compactly represented within the familiar one-dimensional Series and \n",
    "#two-dimensional DataFrame objects.\n",
    "\n",
    "index = [('California', 2000), ('California', 2010),\n",
    "         ('New York', 2000), ('New York', 2010),\n",
    "         ('Texas', 2000), ('Texas', 2010)]\n",
    "populations = [33871648, 37253956,\n",
    "               18976457, 19378102,\n",
    "               20851820, 25145561]\n",
    "pop = pd.Series(populations, index=index)\n",
    "pop\n",
    "\n",
    "pop[('California', 2010):('Texas',2000)]\n",
    "\n",
    "\n",
    "#But the convenience ends there. For example, if you need to select all values from 2010, you'll need to do some messy \n",
    "#(and potentially slow) munging to make it happen:\n",
    "pop[[i for i in pop.index if i[1] == 2010]]\n",
    "\n",
    "\n",
    "#The Better Way: Pandas MultiIndex\n",
    "index = pd.MultiIndex.from_tuples(index)\n",
    "index\n",
    "\n",
    "#reindex\n",
    "pop = pop.reindex(index)\n",
    "pop\n",
    "#Here the first two columns of the Series representation show the multiple index values, \n",
    "#while the third column shows the data. Notice that some entries are missing in the first column: in this \n",
    "#multi-index representation, any blank entry indicates the same value as the line above it.\n",
    "\n",
    "\n",
    "#Now to access all data for which the second index is 2010, we can simply use the Pandas slicing notation:\n",
    "pop[:, 2010]\n",
    "\n",
    "\n",
    "#MultiIndex as extra dimension\n",
    "#. The unstack() method will quickly convert a multiply indexed Series into a conventionally indexed DataFrame:\n",
    "pop_df = pop.unstack()\n",
    "pop_df\n",
    "\n",
    "\n",
    "#Naturally, the stack() method provides the opposite operation:\n",
    "pop_df.stack()\n",
    "\n",
    "\n",
    "\n",
    "pop_df = pd.DataFrame({'total': pop,\n",
    "                       'under18': [9267089, 9284094,\n",
    "                                   4687374, 4318033,\n",
    "                                   5906301, 6879014]})\n",
    "pop_df\n",
    "\n",
    "\n",
    "f_u18 = pop_df['under18'] /pop_df['total']\n",
    "f_u18.unstack()\n",
    "\n",
    "\n",
    "#Methods of MultiIndex Creation\n",
    "#The most straightforward way to construct a multiply indexed Series or DataFrame is to simply pass a list of two or \n",
    "#more index arrays to the constructor. For example:\n",
    "df = pd.DataFrame(np.random.rand(4, 2),\n",
    "                  index=[['a', 'a', 'b', 'b'], [1, 2, 1, 2]],\n",
    "                  columns=['data1', 'data2'])\n",
    "df\n",
    "\n",
    "\n",
    "#Explicit MultiIndex constructors\n",
    "#you can construct the MultiIndex from a simple list of arrays giving the index values within each level:\n",
    "pd.MultiIndex.from_arrays([['a', 'a', 'b', 'b'], [1, 2, 1, 2]])\n",
    "\n",
    "\n",
    "#You can construct it from a list of tuples giving the multiple index values of each point:\n",
    "pd.MultiIndex.from_tuples([('a', 1), ('a', 2), ('b', 1), ('b', 2)])\n",
    "\n",
    "#You can even construct it from a Cartesian product of single indices:\n",
    "pd.MultiIndex.from_product([['a','b'],[1,2]])\n",
    "\n",
    "\n",
    "\n",
    "#MultiIndex level namesÂ¶\n",
    "#Sometimes it is convenient to name the levels of the MultiIndex. This can be accomplished by passing the names argument \n",
    "#to any of the above MultiIndex constructors, or by setting the names attribute of the index after the fact:\n",
    "pop.index.names = ['state', 'year']\n",
    "pop\n",
    "\n",
    "\n",
    "\n",
    "#MultiIndex for columns\n",
    "# hierarchical indices and columns\n",
    "index = pd.MultiIndex.from_product([[2013, 2014], [1, 2]],\n",
    "                                   names=['year', 'visit'])\n",
    "columns = pd.MultiIndex.from_product([['Bob', 'Guido', 'Sue'], ['HR', 'Temp']],\n",
    "                                     names=['subject', 'type'])\n",
    "\n",
    "# mock some data\n",
    "data = np.round(np.random.randn(4, 6), 1)\n",
    "data[:, ::2] *= 10\n",
    "data += 37\n",
    "\n",
    "# create the DataFrame\n",
    "health_data = pd.DataFrame(data, index=index, columns=columns)\n",
    "health_data\n",
    "\n",
    "\n",
    "#Other types of indexing and selection work as well; for example, selection based on Boolean masks:\n",
    "pop[pop>20000000]\n",
    "\n",
    "\n",
    "\n",
    "#Multiply indexed DataFrames\n",
    "health_data\n",
    "\n",
    "#Remember that columns are primary in a DataFrame, and the syntax used for multiply indexed Series applies to the columns. \n",
    "#For example, we can recover Guido's heart rate data with a simple operation:\n",
    "health_data['Guido', 'HR']\n",
    "\n",
    "#Also, as with the single-index case, we can use the loc, iloc, and ix indexers, For example:\n",
    "health_data.iloc[:2, :2]\n",
    "\n",
    "health_data.loc[:, ('Bob', 'HR')]\n",
    "\n",
    "\n",
    "#slicing, IndexSlice \n",
    "idx = pd.IndexSlice\n",
    "health_data.loc[idx[:, 1], idx[:, 'HR']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "57ecec69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'df1'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'df2'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'pd.concat([df1, df2])'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'df3'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'df4'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"pd.concat([df3, df4], axis='col')\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Combining Datasets: Concat and Append\n",
    "\n",
    "def make_df(cols, ind):\n",
    "    \"\"\"Quickly make a DataFrame\"\"\"\n",
    "    data = {c: [str(c) + str(i) for i in ind]\n",
    "            for c in cols}\n",
    "    return pd.DataFrame(data, ind)\n",
    "\n",
    "# example DataFrame\n",
    "make_df('ABC', range(3))\n",
    "\n",
    "df1 = make_df('AB', [1, 2])\n",
    "df2 = make_df('AB', [3, 4])\n",
    "display('df1', 'df2', 'pd.concat([df1, df2])')\n",
    "\n",
    "\n",
    "\n",
    "df3 = make_df('AB', [0, 1])\n",
    "df4 = make_df('CD', [0, 1])\n",
    "display('df3', 'df4', \"pd.concat([df3, df4], axis='col')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "8b31d5c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'df1'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'df2'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee</th>\n",
       "      <th>group</th>\n",
       "      <th>hire_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Accounting</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jake</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lisa</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sue</td>\n",
       "      <td>HR</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  employee        group  hire_date\n",
       "0      Bob   Accounting       2008\n",
       "1     Jake  Engineering       2012\n",
       "2     Lisa  Engineering       2004\n",
       "3      Sue           HR       2014"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Combining Datasets: Merge and Join\n",
    "df1 = pd.DataFrame({'employee': ['Bob', 'Jake', 'Lisa', 'Sue'],\n",
    "                    'group': ['Accounting', 'Engineering', 'Engineering', 'HR']})\n",
    "df2 = pd.DataFrame({'employee': ['Lisa', 'Bob', 'Jake', 'Sue'],\n",
    "                    'hire_date': [2004, 2008, 2012, 2014]})\n",
    "display('df1', 'df2')\n",
    "\n",
    "df3=pd.merge(df1, df2)\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "73305ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 3, 4, 5],\n",
       "       [4, 5, 6, 7],\n",
       "       [6, 7, 8, 9]])"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([range(i, i + 4) for i in [2, 4, 6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "67fd154c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 5],\n",
       "       [7, 6]])"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Array\n",
    "import numpy as np\n",
    "np.random.seed(0)  # seed for reproducibility\n",
    "\n",
    "x1 = np.random.randint(10, size=6)  # One-dimensional array\n",
    "x1\n",
    "x2=np.random.randint(10, size=(3,4))\n",
    "x2\n",
    "x3=np.random.randint(10, size=(3,4,5))\n",
    "x3\n",
    "\n",
    "#print(\"x3 ndim: \", x3.ndim)\n",
    "#print(\"x3 shape:\", x3.shape)\n",
    "#print(\"x3 size: \", x3.size)\n",
    "#print('dtype:', x3.dtype)\n",
    "\n",
    "\n",
    "#print(\"itemsize:\", x3.itemsize, \"bytes\")\n",
    "#print(\"nbytes:\", x3.nbytes, \"bytes\")\n",
    "\n",
    "\n",
    "\n",
    "x2\n",
    "x2_sub=x2[:2, :2]\n",
    "x2_sub\n",
    "\n",
    "\n",
    "#copy of arrays\n",
    "x2_sub_copy=x2[:2,:2].copy()\n",
    "x2_sub_copy\n",
    "x2_sub_copy[0,0]=42\n",
    "x2_sub_copy\n",
    "x2_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de798ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get timelocal for the start of streak\n",
    "df_new['streak_time'] = df_new.loc[df_new.start_of_streak == True]['time_local']\n",
    "\n",
    "# convert streak start time to datetime\n",
    "df_new['streak_time'] = pd.to_datetime(df_new['streak_time'])\n",
    "\n",
    "# fill null values from previous values by using forward filling\n",
    "df_new = df_new.fillna(method='ffill')\n",
    "\n",
    "# calculate delta in minutes\n",
    "df_new['delta'] = (df_new['time_local'] - df_new['streak_time'] \n",
    "                  ).dt.total_seconds() / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85ddce2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
